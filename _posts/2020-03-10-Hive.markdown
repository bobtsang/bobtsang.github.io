---
layout: post
title:  "Hive"
date:   2020-03-10 22:59:07 +0800
---
Apache Hive development notes

#### Introduction

 > Hive offers no support for row-level inserts, updates, and deletes. Hive doesn’t support transactions. Hive adds extensions to provide better performance in the context of Hadoop and to integrate with custom extensions and even external programs.

#### Data Units

- Databases: Namespace function to avoid naming conflicts
- Tables
- Partitions
- Buckets: Data in each partition may in turn be divided into Buckets

#### Type System

##### Primitive Types
- Integers
  - `TINYINT`
  - `SMALLINT`
  - `INT`
  - `BIGINT`
- Boolean type
- Floating point numbers
  - `FLOAT`: single precision
  - `DOUBLE`: Double precision
- Fixed point numbers
  - `DECIMAL`
- String types
  - `STRING`
  - `VARCHAR`: maximum length specified
  - `CHAR`: with defined length
- Date and time types
  - `TIMESTAMP`
  - `TIMESTAMP WITH LOCAL TIME ZONE`
  - `DATE`

##### Notes

1. String can be specified within single quote or double quote.
2. `TIMESTAMP` are interpreted as UTC times. `to_utc_timestamp` and `from_utc_timestamp` built-in functions are offered.
3. Hierarchy

![tree is not for this.use things properly]({{site.baseurl}}/resources/hive_type_hierarchy.png)


#### Hive Anti-pattern

>However, Hive is implemented and used in ways that are very different from conventional relational databases. Often, users try to carry over paradigms from the relational world that are actually Hive anti-patterns.

- Table-by-day
- Over partitioning
- Unique keys and normalisation
    >“Hive, however, does not have the concept of primary keys or automatic, sequence-based key generation. Joins should be avoided in favor of denormalized data, when feasible.”
  
  - Array, Map and Struct: one-to-many data inside a single row.
  - The primary reason of denormalisation is to avoid <b> disk seek</b>, but with greater risk of inconsistency

- > Hive has a special syntax for producing multple aggregations from a single pass through a source of data, rather than rescanning it for each aggregation

#### Reference

1. [Learning notes](https://www.notion.so/bobzeng/Hive-32d05a84ec344fdfac1ffd99cc13bb79)
2. [Apache Hive Documentation](https://cwiki.apache.org/confluence/display/Hive)
3. Programming Hive, Edward Capriolo etc., 2012
4. [Hive Tutorial](https://cwiki.apache.org/confluence/display/Hive/Tutorial)