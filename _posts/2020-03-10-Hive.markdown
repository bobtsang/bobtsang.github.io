---
layout: post
title:  "Hive"
date:   2020-03-10 22:59:07 +0800
---

#### Introduction

On top of `Apache Hadoop`, Hive is doing the following

- SQL interface
- Access to files either directly in `Apache HDFS` or in other data storage system like `Apache HBase`
- Query execution via `Apache Tez`, `Apache Spark` or `MapReduce`

 > Hive offers no support for row-level inserts, updates, and deletes. Hive doesn’t support transactions. Hive adds extensions to provide better performance in the context of Hadoop and to integrate with custom extensions and even external programs.

#### Architecture

 ![Hive Architecture](https://cwiki.apache.org/confluence/download/attachments/27362072/system_architecture.png?version=1&modificationDate=1414560669000&api=v2)

##### HDFS

- `NameNode`: a master server that manages the file system namespace and regulates access to files by clients
- `DataNode`: manage Data storage

##### Compiler

`Compiler` does the following:

- **Parser**:parses the query;Transform a query string to a parse tree representation
- **Semantic Analyzer**: does semantic analysis on the different query blocks
- **Logical Plan Generator**
- **Query Plan Generator**: converts the logical plan into a series of map-reduce jobs.eventually generates an execution plan with the help of the table and partition metadata looked up from the `Metastore`.

##### Metastore

`Metastore` stores in the structure information including table, columns and partitions.

- Data abstraction
- Data discovery

#### File Types

- Avro Files
- ORC Files
- Parquet
- Comprssed Data Storage
- LZO compression

#### Data Units

- Databases: Namespace function to avoid naming conflicts
- Tables
  - Each table has a corresponding HDFS directory.
  - Managed and external tables
    > CREATE TABLE IF NOT EXISTS
    > CREATE EXTERNAL TABLE IF NOT EXISTS
    > “Because it’s external, Hive does not assume it owns the data. Therefore, dropping the table does not delete the data, although the metadata for the table will be deleted.”

- Partitions
- Buckets: Data in each partition may in turn be divided into Buckets; Each bucket is stored as a file in the partition directory.

#### Type System

##### Primitive Types

- Integers
  - `TINYINT`
  - `SMALLINT`
  - `INT`
  - `BIGINT`
- Boolean type
- Floating point numbers
  - `FLOAT`: single precision
  - `DOUBLE`: Double precision
- Fixed point numbers
  - `DECIMAL`
- String types
  - `STRING`
  - `VARCHAR`: maximum length specified
  - `CHAR`: with defined length
- Date and time types
  - `TIMESTAMP`
  - `TIMESTAMP WITH LOCAL TIME ZONE`
  - `DATE`
- `ARRAY`, `STRUCT` and `MAP`

In the following example, <pre>address</pre> is <pre>struct</pre>.
> “hive> SELECT name, address.city FROM employees;
John Doe    Chicago
Mary Smith  Chicago
Todd Jones  Oak Park
Bill King   Obscuria”

Excerpt From: Edward Capriolo, Dean Wampler, and Jason Rutherglen. “Programming Hive.” Apple Books. 

##### Notes

1. String can be specified within single quote or double quote.
2. `TIMESTAMP` are interpreted as UTC times. `to_utc_timestamp` and `from_utc_timestamp` built-in functions are offered.
3. Hierarchy

![tree is not for this.use things properly]({{site.baseurl}}/resources/hive_type_hierarchy.png)


#### Hive Anti-pattern

>However, Hive is implemented and used in ways that are very different from conventional relational databases. Often, users try to carry over paradigms from the relational world that are actually Hive anti-patterns.

- Table-by-day
- Over partitioning
- Unique keys and normalisation
    >“Hive, however, does not have the concept of primary keys or automatic, sequence-based key generation. Joins should be avoided in favor of denormalized data, when feasible.”
  
  - Array, Map and Struct: one-to-many data inside a single row.
  - The primary reason of denormalisation is to avoid <b> disk seek</b>, but with greater risk of inconsistency

- > Hive has a special syntax for producing multple aggregations from a single pass through a source of data, rather than rescanning it for each aggregation

#### HiveSQL

>These scripts can be written in any language using a simple row-based streaming interface – read rows from standard input and write out rows to standard output. This flexibility comes at a cost of a performance hit caused by converting rows from and to strings. However, we have seen that users do not mind this given that they can implement their scripts in the language of their choice. 

##### Query data for similar column names

<code>hive> SELECT symbol, `price.*` FROM stocks;</code>

##### Type conversion

If types are different.
>“Otherwise, if the types differ, then the value of the smaller of the two types is promoted to wider type of the other value. (Wider in the sense that a type with more bytes can hold a wider range of values.)”

##### Table generating functions

##### Floating-Point Comparisons

“Actually, it doesn’t work. Here’s why. The number 0.2 can’t be represented exactly in a FLOAT or DOUBLE. (See http://docs.oracle.com/cd/E19957-01/806-3568/ncg_goldberg.html for an in-depth discussion of floating-point number issues.) In this particular case, the closest exact value is just slightly greater than 0.2, with a few nonzero bits at the least significant end of the number.
To simplify things a bit, let’s say that 0.2 is actually 0.2000001 for FLOAT and 0.200000000001 for DOUBLE, because an 8-byte DOUBLE has more significant digits (after the decimal point). When the FLOAT value from the table is converted to DOUBLE by Hive, it produces the DOUBLE value 0.200000100000, which is greater than 0.200000000001. That’s why the query results appear to use >= not >!” [3]

##### Join Optimizations

> When joining three or more tables, if every `ON` clause uses the same join key, a single `MapReduce` job will be used.

Hive also assumes that the `last` table in the query is the largest.

- `LEFT SEMI JOIN` are more efficient than the more general inner join in that for a given record in the lefthand table, Hive can stop looking for matching records in the righthand table as soon as any match is found.

- `Map-side` joins
If all but one table is small, the largest table can be streamed through the mappers while the small tables are cached in memory. Hive can do all the joining map-side.

- `ORDER BY` vs. `SORT BY` ( + `DISTRIBUTED BY`)
`SORT BY` orders the data only within each reducer (local ordering).

> “We can use DISTRIBUTE BY to ensure that the records for each stock symbol go to the same reducer, then use SORT BY to order the data the way we want.”

#### Table Statistics

Statistics collection process is similar for new and existing tables.

> During the creation, every mapper while copying the rows from the source table in the FileSink operator, gathers statistics for the rows it encounters and publishes them into a Database (possibly MySQL). At the end of the MapReduce job, published statistics are aggregated and stored in the MetaStore.

`ANALYZE TABLE [workspace.]table_name COMPUTE STATISTICS [(column1, column2,...)] [SAMPLE number PERCENT]`

#### Optimisation

- Execution engine
Choose `Tez` instead of `MapReduce` would improve performance
- File format
- Partioning
- Vectorization
- Cost based optimisation
- Indexing

#### Reference

1. [Learning notes](https://www.notion.so/bobzeng/Hive-32d05a84ec344fdfac1ffd99cc13bb79)
2. [Apache Hive Documentation](https://cwiki.apache.org/confluence/display/Hive)
3. Programming Hive, Edward Capriolo etc., 2012
4. [Hive Tutorial](https://cwiki.apache.org/confluence/display/Hive/Tutorial)
5. [Hive - A Warehousing Solution Over a Map-Reduce Framework](https://event.cwi.nl/lsde/papers/hive.pdf), Ashish Thusoo
6. [Hive Architecture in Depth](https://medium.com/plumbersofdatascience/hive-architecture-in-depth-ba44e8946cbc)
7. [The Google File System](https://www.notion.so/bobzeng/The-Google-File-System-52b1a6d925c24d588c8e994d401c21f8), 2003
8. [MapReduce: Simplified Data Processing on Large Clusters](https://static.googleusercontent.com/media/research.google.com/en//archive/mapreduce-osdi04.pdf),2004, Jeffrey Dean
9. [Statistics in Hive](https://cwiki.apache.org/confluence/display/Hive/StatsDev)
10. [Shell Scripts to Check Data Integrity in Hive](https://databaseline.tech/shell-scripts-to-check-data-integrity-in-hive/)
11. [Cost-based optimisation in Hive](https://cwiki.apache.org/confluence/display/Hive/Cost-based+optimization+in+Hive)
